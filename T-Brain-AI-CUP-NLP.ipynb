{"cells":[{"cell_type":"markdown","metadata":{"id":"Xopo9TX0N5QA"},"source":["# Download Files"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30409,"status":"ok","timestamp":1670484212230,"user":{"displayName":"朱自宇","userId":"15701013196506880556"},"user_tz":-480},"id":"iNeT78q4N9ZR","outputId":"cadc5afd-f828-4e09-c3c3-5e3629a44c73"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-08 07:23:01--  https://drive.google.com/uc?export=download&id=1eNfsS5igdw6nKgLeKmX8t7qvGVLXpBc8\n","Resolving drive.google.com (drive.google.com)... 142.251.162.101, 142.251.162.100, 142.251.162.102, ...\n","Connecting to drive.google.com (drive.google.com)|142.251.162.101|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/html]\n","Saving to: ‘Batch_answers - train_data (no-blank).csv’\n","\n","Batch_answers - tra     [ <=>                ]   2.25K  --.-KB/s    in 0s      \n","\n","2022-12-08 07:23:31 (32.2 MB/s) - ‘Batch_answers - train_data (no-blank).csv’ saved [2302]\n","\n"]}],"source":["! wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1eNfsS5igdw6nKgLeKmX8t7qvGVLXpBc8' -O 'Batch_answers - train_data (no-blank).csv'"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18594,"status":"ok","timestamp":1670484230813,"user":{"displayName":"朱自宇","userId":"15701013196506880556"},"user_tz":-480},"id":"nv2q7n9ouqSn","outputId":"031d2c1a-a522-494d-d53c-53c09c451bcf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["## 掛載雲端\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","metadata":{"id":"RU8daQPfSf9k"},"source":["# Initialize and Parameters"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17734,"status":"ok","timestamp":1670484698112,"user":{"displayName":"朱自宇","userId":"15701013196506880556"},"user_tz":-480},"id":"ZS7tt_B8Sezu","outputId":"65d24878-56a4-43f1-e07e-8b0230a35184"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[K     |████████████████████████████████| 5.8 MB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.10.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[K     |████████████████████████████████| 182 kB 73.4 MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[K     |████████████████████████████████| 7.6 MB 50.7 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.9.24)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"]}],"source":["! pip3 install transformers\n","\n","import csv\n","import re\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from transformers import BertTokenizer, BertModel\n","from transformers import BertForSequenceClassification\n","\n","# 斷句字串\n","sep_sentence_regex = '([^?!,.:;]*[?!,.:;]+)'\n","\n","\"\"\"\n","檔案名稱\n","\"\"\"\n","# 訓練資料集\n","trainingset_name = 'Batch_answers - train_data (no-blank).csv'\n","testingset_name = 'Batch_answers - test_data(no_label).csv'\n","\n","# 篩選出要丟進去訓練的 q 和 r \n","trainingset_Q_name = 'training_set_Q.csv'\n","trainingset_R_name = 'training_set_R.csv'\n","\n","# Bert 參數\n","bert_pretrained_model = 'bert-base-uncased'\n","torch_model_output = 'model.dat'"]},{"cell_type":"markdown","metadata":{"id":"S9fDS8vQx3Zz"},"source":["# Util"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"bb7Ngxnbx1kl","executionInfo":{"status":"ok","timestamp":1670484698113,"user_tz":-480,"elapsed":5,"user":{"displayName":"朱自宇","userId":"15701013196506880556"}}},"outputs":[],"source":["# 句子拆分\n","def getSubsentences(paragraph: str, reg: str = \"([^?!,.:;]*[?!,.:;]+)\") -> list:\n","  if type(paragraph) != str:\n","    return []\n","  sentences = list()\n","  paragraph = str(paragraph)\n","  # sentences.append(paragraph)\n","  if len(paragraph) > 1:\n","    sentences = re.split(reg, paragraph)\n","    for i in range(len(sentences)):\n","      sentences[i] = sentences[i].strip()\n","    sentences = list(filter(lambda x : len(x.strip()) > 0, sentences))\n","  else:\n","    sentences = []\n","  return sentences\n","\n","# 句子長度計算\n","def getWords(sentence: str) -> list:\n","  words = list()\n","  words = re.split(\" \", sentence)\n","  words = list(filter(lambda x : len(x.strip()) > 0, words))\n","  return words\n"]},{"cell_type":"markdown","metadata":{"id":"bxE9whzCMmcg"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6QX9bdHWNF7f"},"outputs":[],"source":["# 資料前處理\n","\n","def preprocessTrainSet(mode):\n","    if mode == \"q\":\n","        writeFile = trainingset_Q_name\n","        title1 = 1\n","        title2 = 4\n","    elif mode == \"r\":\n","        writeFile = trainingset_R_name\n","        title1 = 2\n","        title2 = 5\n","\n","    with open(trainingset_name, 'r', encoding='utf-8') as f:\n","        reader = csv.reader(f)\n","        with open(writeFile, 'w', encoding='utf-8', newline='') as outfile:\n","            writer = csv.writer(outfile)\n","\n","            for row in reader:\n","                if row[0] == \"id\":\n","                    writer.writerow([row[0], 'sentence', 'sub_sentence'])\n","                else:\n","                    # 把雙引號處理掉\n","                    rowQ = row[title1][1:-1]\n","                    \n","                    # 先把所有網址全部刪除\n","                    spaceSplit = re.split(' ', rowQ)\n","                    ignoreLIST = []\n","                    for i in range(len(spaceSplit)):\n","                        if spaceSplit[i] == \"http\" and spaceSplit[i+1] == \":\" and spaceSplit[i+2][0:2] == \"//\":\n","                            if i+3 < len(spaceSplit) and spaceSplit[i+3] in [\"...\", \"?\"]:\n","                                ignoreLIST.append(i+3)\n","                                ignoreLIST.append(i+4)\n","                            ignoreLIST.append(i)\n","                            ignoreLIST.append(i+1)\n","                            ignoreLIST.append(i+2)\n","                    rowQ = \"\"\n","                    for i in range(len(spaceSplit)):\n","                        if i not in ignoreLIST:\n","                            if rowQ != \"\":\n","                                rowQ += ' '\n","                            rowQ += spaceSplit[i]\n","                    \n","                    # 斷句\n","                    # splitrow: LIST[string]\n","                    splitrow = re.split(sep_sentence_regex, rowQ)\n","\n","                    # 移除所有因斷句產生的空字串\n","                    while '' in splitrow:\n","                        splitrow.remove('')\n","\n","                    # index\n","                    i = 0\n","                    \n","                    # 前處理: 修正斷句內容\n","                    realtext = []\n","\n","                    while i < len(splitrow):\n","                        # 先去除首尾沒必要的符號\n","                        while splitrow[i] != '' and splitrow[i][0] in [\"`\", \"-\", \"(\", \")\"]:\n","                            splitrow[i] = splitrow[i][1:]\n","                            if splitrow[i][0] == \" \":\n","                                splitrow[i] = splitrow[i][1:]\n","                        while splitrow[i] != '' and splitrow[i][-1] in [\"`\", \"-\", \"(\", \")\"]:\n","                            splitrow[i] = splitrow[i][:-1]\n","                            if splitrow[i][-1] == \" \":\n","                                splitrow[i] = splitrow[i][:-1]\n","                        \n","                        # 0. 空字串\n","                        if splitrow[i] == '':\n","                            pass\n","                        \n","                        # 1. 把刪節號分開的句子連貫起來\n","                        elif i+1 < len(splitrow) and len(splitrow[i]) > 1 and splitrow[i][-2] + splitrow[i][-1] == \"..\":\n","                            realtext.append(splitrow[i] + \" \" + splitrow[i+1].strip())\n","                            i += 1\n","                            \n","                        # 2. 小數或超大數\n","                        elif i+1 < len(splitrow) and splitrow[i][-1] in [\".\", \",\"] and splitrow[i+1][0].isdigit():\n","                            realtext.append(splitrow[i] + splitrow[i+1].strip())\n","                            i += 1\n","\n","                        # 3. 重複的標點符號但是有空格隔開\n","                        elif i+1 < len(splitrow) and splitrow[i+1].strip() in [\"?\", \"!\", \":\", \";\", \".\", \",\"]:\n","                            addSTR = splitrow[i]\n","                            while i+1 < len(splitrow) and splitrow[i+1].strip() in [\"?\", \"!\", \":\", \";\", \".\", \",\"]:\n","                                addSTR += splitrow[i+1]\n","                                i += 1\n","                            realtext.append(addSTR)\n","                        else:\n","                            realtext.append(splitrow[i])\n","                        i += 1\n","\n","                    # 只有一句話\n","                    # 整句丟進模型訓練\n","                    if len(realtext) == 1:\n","                        #writer.writerow([row[0], row[title1], row[title2]])\n","                        pass \n","                    # 兩句話，但整段文本很短\n","                    # 整段當作答案輸出\n","                    elif len(realtext) == 2 and len(re.split(' ', realtext[0] + realtext[1])) < 15:\n","                        pass\n","                    else:    \n","                        i = 0\n","                        ans = \"\"\n","                        for i in range(len(realtext)):\n","                            # 判斷片語或疑問詞\n","                            # 句子太短\n","                            if len(re.split(' ', realtext[i])) <= 6:\n","                                # 結尾是結束符號\n","                                if realtext[i][-1] in [\"?\", \"!\", \".\"]:\n","                                    pass\n","                                # 結尾是停頓符號\n","                                # 忽略\n","                                elif realtext[i][-1] in [\",\", \":\", \";\"]:\n","                                    pass\n","                                # 其他\n","                                # 先忽略\n","                                else:\n","                                    pass\n","                            # 句子夠長，但結尾是','\n","                            # 把句子連貫\n","                            # elif realtext[i][-1] == \",\":\n","                            #     if ans != \"\":\n","                            #         ans += \" \"\n","                            #     ans += realtext[i].strip()\n","\n","\n","                            # 把這句納入訓練資料，結束\n","                            else:\n","                                tempSTR = \"\".join(realtext)\n","                                temp = re.split('([^?!.:;]*[?!.:;]+)', tempSTR)\n","                                # 移除所有因斷句產生的空字串\n","                                while '' in temp:\n","                                    temp.remove('')\n","                                # 處理太長的文本\n","                                while True:\n","                                  len_of_temp = 0\n","                                  for j in temp:\n","                                      len_of_temp += len(re.split(\" \", j))\n","                                  if len_of_temp > 300:\n","                                      delete_str = \"\"\n","                                      for k in temp:\n","                                          if len(k) > len(delete_str):\n","                                            delete_str = k\n","                                      temp.remove(delete_str)\n","                                  else:\n","                                    break\n","                                ans = \"\".join(temp)\n","\n","                                # 寫入訓練資料\n","                                writer.writerow([row[0], ans, row[title2][1:-1]])\n","                                break\n","            outfile.close()\n","        f.close()\n","\n","preprocessTrainSet(\"q\")\n","preprocessTrainSet(\"r\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"executionInfo":{"elapsed":541,"status":"error","timestamp":1670482460328,"user":{"displayName":"黃駿棠","userId":"01299245983671239243"},"user_tz":-480},"id":"Ivoefff1Ys-G","outputId":"5b9065d0-29c4-4f59-9ed1-bd97b7183a46"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-78926082138d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mtraining_set_pre_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingset_Q_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0mtraining_set_pre_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainingset_R_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-78926082138d>\u001b[0m in \u001b[0;36mtraining_set_pre_classification\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtraining_set_pre_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   empty_title = ((df_train[header[0]].isnull()) \\\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_set_Q.csv'"]}],"source":["\"\"\"\n","前處理計算出現頻率\n","\"\"\"\n","def training_set_pre_classification(filename):\n","  df_train = pd.read_csv(filename)\n","  header = df_train.iloc[0].keys()\n","  empty_title = ((df_train[header[0]].isnull()) \\\n","                | (df_train[header[1]].isnull()) \\\n","                | (df_train[header[1]] == '') \\\n","                | (df_train[header[1]] == '0'))\n","  df_train = df_train[~empty_title]\n","\n","  # 篩選句子長度\n","  MAX_LENGTH = 15\n","  df_train = df_train[~(df_train[header[1]].apply(lambda x : len(getSubsentences(x))) > MAX_LENGTH)]\n","\n","  # 隨機抽樣建立訓練資料\n","  SAMPLE_FRAC = 0.6\n","  df_train = df_train.sample(frac=SAMPLE_FRAC, random_state=5180)\n","\n","  \"\"\"\n","  TrainMap:\n","  {\n","    rowID:{\n","      q:\"\",\n","      count:1,\n","      subq:{\n","        subq 1:freq,\n","        subq 2:freq,\n","        subq 3:freq,\n","        ...\n","      }\n","    }\n","  }\n","  \"\"\"\n","  # 計算子句出現在q'中的比例\n","  TrainMap = dict()\n","  for i in range(len(df_train.index)):\n","    rowID = df_train.iloc[i][header[0]]\n","    if not rowID in TrainMap.keys():\n","      TrainMap[rowID] = dict()\n","      TrainMap[rowID]['sent'] = df_train.iloc[i][header[1]]\n","      TrainMap[rowID]['subsent'] = dict()\n","      TrainMap[rowID]['count'] = 1\n","      for sub in getSubsentences(TrainMap[rowID]['sent']):\n","        TrainMap[rowID][\"subsent\"][sub] = 0\n","    for sub in getSubsentences(df_train.iloc[i][header[2]]):\n","      if sub in TrainMap[rowID]['subsent'].keys():\n","        TrainMap[rowID]['subsent'][sub] += 1\n","        TrainMap[rowID]['count'] += 1\n","\n","  for rowID in TrainMap.keys():\n","    if rowID in TrainMap.keys():\n","      words = getWords(TrainMap[rowID]['sent'])\n","      for sub in TrainMap[rowID]['subsent'].keys():\n","        if len(words) + len(getWords(sub)) > 300:\n","          TrainMap[rowID]['sent'] = \" \".join(words[:50] + words[-50:])\n","          words = getWords(TrainMap[rowID]['sent'])\n","        \n","\n","  # 篩選特定子句數\n","  # df_train = df_train[(df_train[\"q'\"].apply(lambda x : len(getSubsentences(x))) == 1)]\n","\n","\n","  # 建立輸出資料\n","  # id, q, subq, freq\n","  df2_data = dict()\n","  #df2_data[\"ID\"] = list()\n","  df2_data[\"sent\"] = list()\n","  df2_data[\"subsent\"] = list()\n","  df2_data[\"freq\"] = list()\n","\n","  for key in TrainMap.keys():\n","    total = sum(TrainMap[key]['subsent'].values())\n","    if total == 0:\n","      continue\n","    for subq in TrainMap[key]['subsent'].keys():\n","      #df2_data[\"ID\"].append(key)\n","      df2_data[\"sent\"].append(TrainMap[key][\"sent\"])\n","      df2_data[\"subsent\"].append(subq)\n","      freq = float(TrainMap[key][\"subsent\"][subq]/TrainMap[key][\"count\"])\n","      # 出現頻率0-1.0分類到類別0-9\n","      if freq >= 0.75:\n","          freq = 5\n","      elif freq >= 0.50:\n","          freq = 4\n","      elif freq >= 0.25:\n","          freq = 3\n","      elif freq >= 0.10:\n","          freq = 2\n","      elif freq > 0:\n","          freq = 1\n","      else:\n","          freq = 0\n","      df2_data[\"freq\"].append(freq)\n","\n","  df2 = pd.DataFrame(df2_data)\n","  df2.to_csv(filename.split(\".\")[0] + \"_classification.tsv\", sep=\"\\t\", index=False)  \n","  print(df2.head(10))\n","\n","  \n","\n","training_set_pre_classification(trainingset_Q_name)\n","training_set_pre_classification(trainingset_R_name)"]},{"cell_type":"markdown","metadata":{"id":"_eoBrtbZk-2d"},"source":["# Bert fine tune training\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495,"referenced_widgets":["9544d0f715e7407c8bdf10d3312a12a1","b5b48497c18947b587173500d37b5f0d","b45a0ed4e2324897a05ecd5cb2877c8f","f7075a22ee3048d0b297ed19bbaa1b82","ad38d59a91f740628869925c8373d149","32af8c4e426c47ae8665590dc36814cb","609bb8e120fe484ea72fb4212da7f48c","5906c5ff8e3d47039127db76d6bfec16","9b9664e5d5d044d2b051b5eb3bd0ef42","37de6056527b44a2a4548b4d6aaf06d1","041fcf91d4c5426ca705365c76a1a5d8","21dab3de7917438fa813e13d112023bc","f8efb18533c44468bbbb3c65fbd7ce1e","8293949f27d840faba28c67b1bc7e349","89eb4ea7348a408491cf79a023a26764","a31a2dc521dc4d36b805425a767da4a7","aaaae1666914459d8e96b9d89ceff593","997a146478d34a70bcb8c34c1c72c917","09fe99c50a594758b31060fb336b0e6a","793d5a9909174d6c9e81c65e750e50f6","696780ae21a44599b074e011521b11aa","d84d564867d64f97b0b3925806c78aa7","90446af5e6934690a721295b1f2ff5f0","9fd2859a34304d0aace16e0c2eed707c","f07c1df2094b4afdb9121a4605619473","af12231d2cdc498882c4464308c24643","96a478bdaccf4d5484a8b1716ea1618d","a479082a2d224991bd4a71c9a3a803b8","ba213c6c2f6941f8a2b2fba8e39c56bd","de2e60d8c4134e3088a54db8ad65d6ee","a72ecf9c88e042bfbdc1de844a71f011","fa83d81a2f3d4d849b3f0b6ca53cfc17","d04a84b0d1f54f04a1dd73949bd29361"]},"executionInfo":{"elapsed":1674,"status":"error","timestamp":1670485477752,"user":{"displayName":"朱自宇","userId":"15701013196506880556"},"user_tz":-480},"id":"j5doOVIvQCkX","outputId":"4183bfe1-66f2-4390-c162-881cf24c529c"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9544d0f715e7407c8bdf10d3312a12a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21dab3de7917438fa813e13d112023bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90446af5e6934690a721295b1f2ff5f0"}},"metadata":{}},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-f20a1aafca0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceSimilarityDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainingset_Q_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_classification.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-f20a1aafca0a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode, filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 如果讀入模式不是train, test直接報錯\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m  \u001b[0;31m# BertTokenizer 小寫英文\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'training_set_Q_classification.tsv'"]}],"source":["\"\"\"\n","實作一個可以用來讀取訓練 / 測試集的 Dataset，這是你需要徹底了解的部分。\n","此 Dataset 每次將 tsv 裡的一筆成對句子轉換成 BERT 相容的格式，並回傳 3 個 tensors：\n","- tokens_tensor：兩個句子合併後的索引序列，包含 [CLS] 與 [SEP]\n","- segments_tensor：可以用來識別兩個句子界限的 binary tensor\n","- label_tensor：將分類標籤轉換成類別索引的 tensor, 如果是測試集則回傳 None\n","\"\"\"\n","tokenizer = BertTokenizer.from_pretrained(bert_pretrained_model) \n","    \n","class SentenceSimilarityDataset(Dataset): # 繼承自torch的Dataset\n","    # 初始化設定\n","    def __init__(self, mode, filename):\n","        assert mode in [\"train\", \"test\"] # 如果讀入模式不是train, test直接報錯\n","        self.mode = mode\n","        self.df = pd.read_csv(filename, sep=\"\\t\").fillna(\"\")\n","        self.len = len(self.df)\n","        self.tokenizer = tokenizer  # BertTokenizer 小寫英文\n","    \n","    # 定義回傳一筆訓練 / 測試數據的函式\n","    def __getitem__(self, idx):\n","        if self.mode == \"test\":\n","            text_sentence, text_subs = self.df.iloc[idx, :2].values\n","            tensor_freq_subs = None\n","        else:\n","            text_sentence, text_subs, freq_subs = self.df.iloc[idx, :].values\n","            tensor_freq_subs = torch.tensor(freq_subs)\n","        # 建立 BERT 起始子 [CLS] 加入第一個句子並加入分隔符號 [SEP]\n","        word_input = [\"[CLS]\"]\n","        tokens_sentence = self.tokenizer.tokenize(text_sentence)\n","        word_input += tokens_sentence + [\"[SEP]\"]\n","        len_sentence = len(word_input)\n","        \n","        # 加入第二個句子並加入分隔符號 [SEP]\n","        tokens_subs = self.tokenizer.tokenize(text_subs)\n","        word_input += tokens_subs + [\"[SEP]\"]\n","        len_subs = len(word_input) - len_sentence\n","        \n","        # 將整個 token 序列轉換成索引序列\n","        ids = self.tokenizer.convert_tokens_to_ids(word_input)\n","        tokens_tensor = torch.tensor(ids)\n","        \n","        # 將第一句包含 [SEP] 的 token 位置設為 0，其他為 1 表示第二句\n","        segments_tensor = torch.tensor([0] * len_sentence + [1] * len_subs, dtype=torch.long)\n","        \n","        return (tokens_tensor, segments_tensor, tensor_freq_subs)\n","\n","    def __len__(self):\n","        return self.len\n","    \n","    \n","# 初始化一個專門讀取訓練樣本的 Dataset，使用中文 BERT 斷詞\n","trainset = SentenceSimilarityDataset(\"train\", trainingset_Q_name.split(\".\")[0] + \"_classification.tsv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670306209041,"user":{"displayName":"黃駿棠","userId":"01299245983671239243"},"user_tz":-480},"id":"yAgPBjaAhuLB","outputId":"bd529187-40a0-4190-f46f-29bb8fe01b95"},"outputs":[{"name":"stdout","output_type":"stream","text":["[原始文本]\n","句子 1：No . The fetus does not have all of these things up and running until birth . The baby needs more than nutrition . It relies on the mother 's anti-bodies for it 's immune system ( even AFTER birth to some degree ) , it does not breath or take in oxygen on it 's own , and none of body systems are developed until late in the pregnancy .\n","句子 2：No .\n","出現頻率  ：2\n","\n","--------------------\n","\n","[Dataset 回傳的 tensors]\n","tokens_tensor  ：tensor([  101,  2053,  1012,  1996, 10768,  5809,  2515,  2025,  2031,  2035,\n","         1997,  2122,  2477,  2039,  1998,  2770,  2127,  4182,  1012,  1996,\n","         3336,  3791,  2062,  2084, 14266,  1012,  2009, 16803,  2006,  1996,\n","         2388,  1005,  1055,  3424,  1011,  4230,  2005,  2009,  1005,  1055,\n","        11311,  2291,  1006,  2130,  2044,  4182,  2000,  2070,  3014,  1007,\n","         1010,  2009,  2515,  2025,  3052,  2030,  2202,  1999,  7722,  2006,\n","         2009,  1005,  1055,  2219,  1010,  1998,  3904,  1997,  2303,  3001,\n","         2024,  2764,  2127,  2397,  1999,  1996, 10032,  1012,   102,  2053,\n","         1012,   102])\n","\n","segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 1, 1, 1])\n","\n","label_tensor   ：2\n","\n","--------------------\n","\n","[還原 tokens_tensors]\n","[CLS] no . the fe ##tus does not have all of these things up and running until birth . the baby needs more than nutrition . it relies on the mother ' s anti - bodies for it ' s immune system ( even after birth to some degree ) , it does not breath or take in oxygen on it ' s own , and none of body systems are developed until late in the pregnancy . [SEP] no . [SEP]\n","\n"]}],"source":["# 挑選第一個資料檢視\n","sample_idx = 0\n","\n","# 將原始文本拿出做比較\n","text_sentence, text_subs, freq_subs = trainset.df.iloc[sample_idx].values\n","\n","# 利用剛剛建立的 Dataset 取出轉換後的 id tensors\n","tokens_tensor, segments_tensor, freq = trainset[sample_idx]\n","\n","# 將 tokens_tensor 還原成文本\n","tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n","combined_text = \" \".join(tokens)\n","\n","# 渲染前後差異，毫無反應就是個 print。可以直接看輸出結果\n","print(f\"\"\"[原始文本]\n","句子 1：{text_sentence}\n","句子 2：{text_subs}\n","出現頻率  ：{freq_subs}\n","\n","--------------------\n","\n","[Dataset 回傳的 tensors]\n","tokens_tensor  ：{tokens_tensor}\n","\n","segments_tensor：{segments_tensor}\n","\n","label_tensor   ：{freq}\n","\n","--------------------\n","\n","[還原 tokens_tensors]\n","{combined_text}\n","\"\"\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"executionInfo":{"elapsed":384,"status":"error","timestamp":1670485533240,"user":{"displayName":"朱自宇","userId":"15701013196506880556"},"user_tz":-480},"id":"FdY8IgOwgEV5","outputId":"7a9e6f22-9337-447b-f446-f7c2061ca828"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-23422a32aab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_mini_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'trainset' is not defined"]}],"source":["\"\"\"\n","實作可以一次回傳一個 mini-batch 的 DataLoader\n","這個 DataLoader 吃我們上面定義的 `SentenceSimilarityDataset`，\n","回傳訓練 BERT 時會需要的 4 個 tensors：\n","- tokens_tensors  : (batch_size, max_seq_len_in_batch)\n","- segments_tensors: (batch_size, max_seq_len_in_batch)\n","- masks_tensors   : (batch_size, max_seq_len_in_batch)\n","- label_ids       : (batch_size)\n","\"\"\"\n","\n","# 這個函式的輸入 `samples` 是一個 list，裡頭的每個 element 都是\n","# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n","# - tokens_tensor\n","# - segments_tensor\n","# - label_tensor\n","# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n","\n","def create_mini_batch(samples):\n","    tokens_tensors = [s[0] for s in samples]\n","    segments_tensors = [s[1] for s in samples]\n","    \n","    # 測試集有 labels\n","    if samples[0][2] is not None:\n","        label_ids = torch.stack([s[2] for s in samples])\n","    else:\n","        label_ids = None\n","    \n","    # zero pad 到同一序列長度\n","    tokens_tensors = pad_sequence(tokens_tensors, batch_first=True)\n","    segments_tensors = pad_sequence(segments_tensors, batch_first=True)\n","    \n","    # attention masks，將 tokens_tensors 裡頭不為 zero padding\n","    # 的位置設為 1 讓 BERT 只關注這些位置的 tokens\n","    masks_tensors = torch.zeros(tokens_tensors.shape, dtype=torch.long)\n","    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0, 1)\n","    \n","    \n","\n","    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n","\n","\n","# 初始化一個每次回傳 64 個訓練樣本的 DataLoader\n","# 利用 `collate_fn` 將 list of samples 合併成一個 mini-batch 是關鍵\n","BATCH_SIZE = 32\n","trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, collate_fn=create_mini_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1670306209042,"user":{"displayName":"黃駿棠","userId":"01299245983671239243"},"user_tz":-480},"id":"uyV1c8LRg6Ta","outputId":"723765e5-8327-4909-b41b-47740caf9c8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","tokens_tensors.shape   = torch.Size([32, 105]) \n","tensor([[ 101, 2053, 1012,  ...,    0,    0,    0],\n","        [ 101, 2053, 1012,  ...,    0,    0,    0],\n","        [ 101, 2053, 1012,  ...,    0,    0,    0],\n","        ...,\n","        [ 101, 2025, 2469,  ...,    0,    0,    0],\n","        [ 101, 2025, 2469,  ...,    0,    0,    0],\n","        [ 101, 2025, 2469,  ...,    0,    0,    0]])\n","------------------------\n","segments_tensors.shape = torch.Size([32, 105])\n","tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]])\n","------------------------\n","masks_tensors.shape    = torch.Size([32, 105])\n","tensor([[1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        ...,\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0],\n","        [1, 1, 1,  ..., 0, 0, 0]])\n","------------------------\n","label_ids.shape        = torch.Size([32])\n","tensor([2, 2, 2, 2, 2, 0, 0, 0, 0, 4, 2, 0, 3, 3, 3, 3, 0, 0, 4, 0, 0, 0, 4, 2,\n","        0, 3, 3, 0, 0, 0, 0, 0])\n","\n"]}],"source":["data = next(iter(trainloader))\n","\n","tokens_tensors, segments_tensors, \\\n","    masks_tensors, label_ids = data\n","\n","print(f\"\"\"\n","tokens_tensors.shape   = {tokens_tensors.shape} \n","{tokens_tensors}\n","------------------------\n","segments_tensors.shape = {segments_tensors.shape}\n","{segments_tensors}\n","------------------------\n","masks_tensors.shape    = {masks_tensors.shape}\n","{masks_tensors}\n","------------------------\n","label_ids.shape        = {label_ids.shape}\n","{label_ids}\n","\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":295,"referenced_widgets":["d380c40fcc684c2c992c55daa1fee568","71f9b917b402439191d97dc1c6dbf9d4","1c5eb6beea874ce888617b1d61040e87","bd94ade2425b422995069d9b258cd6f3","1979d4beacc244179d42202c43910762","c7a28622dc554b1a804af4552adc8ffd","6691ec28cd384d20a29c1a3c0130fa6c","3a7723f2371d46cea350006322e8ba5f","d4fb458b31d146c7881702f4b60d1796","79324c6387d149f0b212cb2b0abaff14","acabe54c777940c6bf28fa6bc323c61b"]},"executionInfo":{"elapsed":26062,"status":"ok","timestamp":1670420461642,"user":{"displayName":"黃駿棠","userId":"17961194170159173980"},"user_tz":-480},"id":"0BkjiCmAijjN","outputId":"44abddd8-c73b-459f-c564-e17c93d31f46"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d380c40fcc684c2c992c55daa1fee568"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n","name            module\n","----------------------\n","bert:embeddings\n","bert:encoder\n","bert:pooler\n","dropout         Dropout(p=0.1, inplace=False)\n","classifier      Linear(in_features=768, out_features=6, bias=True)\n"]}],"source":["model = BertForSequenceClassification.from_pretrained(\n","    bert_pretrained_model, num_labels = 6) \n","\n","# high-level 顯示此模型裡的 modules\n","print(\"\"\"\n","name            module\n","----------------------\"\"\")\n","for name, module in model.named_children():\n","    if name == \"bert\":\n","        for n, _ in module.named_children():\n","            print(f\"{name}:{n}\")\n","    else:\n","        print(\"{:15} {}\".format(name, module))"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":253},"executionInfo":{"elapsed":302,"status":"error","timestamp":1670485558803,"user":{"displayName":"朱自宇","userId":"15701013196506880556"},"user_tz":-480},"id":"V2qoIALBj3eT","outputId":"7549e629-2da4-4bbe-fd0e-0d857aae5d0d"},"outputs":[{"output_type":"stream","name":"stdout","text":["device: cuda:0\n"]},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-075281524628>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"device:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_acc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"classification acc:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"]}],"source":["def get_predictions(model, dataloader, compute_acc=False):\n","    predictions = None\n","    correct = 0\n","    total = 0\n","      \n","    with torch.no_grad():\n","        # 遍巡整個資料集\n","        for data in dataloader:\n","            # 將所有 tensors 移到 GPU 上\n","            if next(model.parameters()).is_cuda:\n","                data = [t.to(\"cuda:0\") for t in data if t is not None]\n","            \n","            \n","            # 別忘記前 3 個 tensors 分別為 tokens, segments 以及 masks\n","            # 且強烈建議在將這些 tensors 丟入 `model` 時指定對應的參數名稱\n","            tokens_tensors, segments_tensors, masks_tensors = data[:3]\n","            outputs = model(input_ids=tokens_tensors, \n","                            token_type_ids=segments_tensors, \n","                            attention_mask=masks_tensors.unsqueeze(1))\n","            \n","            logits = outputs[0]\n","            _, pred = torch.max(logits.data, 1)\n","            \n","            # 用來計算訓練集的分類準確率\n","            if compute_acc:\n","                labels = data[3]\n","                total += labels.size(0)\n","                correct += (pred == labels).sum().item()\n","                \n","            # 將當前 batch 記錄下來\n","            if predictions is None:\n","                predictions = pred\n","            else:\n","                predictions = torch.cat((predictions, pred))\n","    \n","    if compute_acc:\n","        acc = correct / total\n","        return predictions, acc\n","    return predictions\n","    \n","# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(\"device:\", device)\n","model = model.to(device)\n","_, acc = get_predictions(model, trainloader, compute_acc=True)\n","print(\"classification acc:\", acc)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1670306483647,"user":{"displayName":"黃駿棠","userId":"01299245983671239243"},"user_tz":-480},"id":"lEHc__2MneoC","outputId":"63c90c50-04dd-4970-d4b8-0baa8258873b"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","整個分類模型的參數量：109486854\n","線性分類器的參數量：4614\n","\n"]}],"source":["def get_learnable_params(module):\n","    return [p for p in module.parameters() if p.requires_grad]\n","     \n","model_params = get_learnable_params(model)\n","clf_params = get_learnable_params(model.classifier)\n","\n","print(f\"\"\"\n","整個分類模型的參數量：{sum(p.numel() for p in model_params)}\n","線性分類器的參數量：{sum(p.numel() for p in clf_params)}\n","\"\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":6876601,"status":"ok","timestamp":1670314714210,"user":{"displayName":"黃駿棠","userId":"01299245983671239243"},"user_tz":-480},"id":"nVqj8Rg-njpy","outputId":"dc18f9c9-f99a-4b4a-bd63-43c6f4810836"},"outputs":[{"name":"stdout","output_type":"stream","text":["[epoch 1] loss: 949.114, acc: 0.513\n","[epoch 2] loss: 858.487, acc: 0.538\n","[epoch 3] loss: 791.536, acc: 0.565\n","[epoch 4] loss: 694.887, acc: 0.624\n","[epoch 5] loss: 583.935, acc: 0.666\n","[epoch 6] loss: 488.458, acc: 0.676\n","[epoch 7] loss: 430.518, acc: 0.679\n","[epoch 8] loss: 368.116, acc: 0.689\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m<ipython-input-11-075281524628>\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(model, dataloader, compute_acc)\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# 將當前 batch 記錄下來\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","\n","# 訓練模式\n","model.train()\n","\n","# 使用 Adam Optim 更新整個分類模型的參數\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n","\n","# 14\n","EPOCHS = 5  # 幸運數字\n","for epoch in range(EPOCHS):\n","    \n","    running_loss = 0.0\n","    for data in trainloader:\n","        \n","        tokens_tensors, segments_tensors, \\\n","        masks_tensors, labels = [t.to(device) for t in data]\n","\n","        # 將參數梯度歸零\n","        optimizer.zero_grad()\n","        # forward pass\n","        outputs = model(input_ids=tokens_tensors, \n","                        token_type_ids=segments_tensors, \n","                        attention_mask=masks_tensors, \n","                        labels=labels)\n","        loss = outputs[0]\n","        # backward\n","        loss.backward()\n","        optimizer.step()\n","\n","\n","        # 紀錄當前 batch loss\n","        running_loss += loss.item()\n","        \n","    # 計算分類準確率\n","    _, acc = get_predictions(model, trainloader, compute_acc=True)\n","\n","    print('[epoch %d] loss: %.3f, acc: %.3f' %\n","          (epoch + 1, running_loss, acc))\n","    \n","\n","## epoch 14 batch 32\n","\"\"\"\n","[epoch 1] loss: 260.749, acc: 0.341\n","[epoch 2] loss: 219.299, acc: 0.374\n","[epoch 3] loss: 204.052, acc: 0.430\n","[epoch 4] loss: 189.664, acc: 0.498\n","[epoch 5] loss: 174.917, acc: 0.542\n","[epoch 6] loss: 159.116, acc: 0.587\n","[epoch 7] loss: 143.521, acc: 0.656\n","[epoch 8] loss: 130.123, acc: 0.612\n","[epoch 9] loss: 118.352, acc: 0.693\n","[epoch 10] loss: 108.212, acc: 0.791\n","[epoch 11] loss: 94.720, acc: 0.797\n","[epoch 12] loss: 80.216, acc: 0.837\n","[epoch 13] loss: 70.120, acc: 0.869\n","[epoch 14] loss: 59.383, acc: 0.895\n","CPU times: user 13min 15s, sys: 4min 29s, total: 17min 44s\n","Wall time: 18min 2s\n","\n","\n","\n","_____________batch 32___________________________\n","[epoch 1] loss: 949.114, acc: 0.513\n","[epoch 2] loss: 858.487, acc: 0.538\n","[epoch 3] loss: 791.536, acc: 0.565\n","[epoch 4] loss: 694.887, acc: 0.624\n","[epoch 5] loss: 583.935, acc: 0.666\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"km77D4ne3d27"},"outputs":[],"source":["torch.save(model, torch_model_output)"]},{"cell_type":"markdown","metadata":{"id":"15zj7hmPLHy5"},"source":["# Answer Preprocessing"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"tb9TvXm-LOon","executionInfo":{"status":"ok","timestamp":1670485682292,"user_tz":-480,"elapsed":279,"user":{"displayName":"朱自宇","userId":"15701013196506880556"}}},"outputs":[],"source":["def deleteHTTP(row):\n","    # 先把所有網址全部刪除\n","    spaceSplit = re.split(' ', row)\n","    ignoreLIST = []\n","    for i in range(len(spaceSplit)):\n","        if spaceSplit[i] == \"http\" and spaceSplit[i+1] == \":\" and spaceSplit[i+2][0:2] == \"//\":\n","            if i+3 < len(spaceSplit) and spaceSplit[i+3] in [\"...\", \"?\"]:\n","                ignoreLIST.append(i+3)\n","                ignoreLIST.append(i+4)\n","            ignoreLIST.append(i)\n","            ignoreLIST.append(i+1)\n","            ignoreLIST.append(i+2)\n","    ans = \"\"\n","    for i in range(len(spaceSplit)):\n","        if i not in ignoreLIST:\n","            if ans != \"\":\n","                ans += ' '\n","            ans += spaceSplit[i]\n","                    \n","    return ans\n","\n","\n","def generateAns(row):\n","    # 篩選特定句子輸出\n","    superKeys = list([\n","        \"eg . \",\n","    ])\n","    for key in superKeys:\n","      findIdx = row.find(key)\n","      if findIdx != -1:\n","        row = row[findIdx+len(key):]\n","\n","    Sentence_Min_length = 5\n","    # 斷句\n","    # splitrow: LIST[string]\n","    splitrow = re.split('([^?!,.:;]*[?!,.:;]+)', row)\n","        \n","    # 移除所有因斷句產生的空字串\n","    while '' in splitrow:\n","        splitrow.remove('')\n","\n","    # index\n","    i = 0\n","         \n","    ans = \"\"\n","    writerow = \"\"\n","\n","    realtext = list()\n","\n","    while i < len(splitrow):\n","        # 先去除首尾沒必要的符號\n","        while splitrow[i] != '' and splitrow[i][0] in [\"`\", \"-\", \"(\", \")\", \"#\"]:\n","            splitrow[i] = splitrow[i][1:]\n","            if splitrow[i][0] == \" \":\n","                splitrow[i] = splitrow[i][1:]\n","        while splitrow[i] != '' and splitrow[i][-1] in [\"`\", \"-\", \"(\", \")\", \"#\"]:\n","            splitrow[i] = splitrow[i][:-1]\n","            if splitrow[i][-1] == \" \":\n","                splitrow[i] = splitrow[i][:-1]\n","                    \n","        # 0. 空字串\n","        if splitrow[i] == '':\n","            pass\n","\n","        # 1. 把刪節號分開的句子連貫起來\n","        elif i+1 < len(splitrow) and len(splitrow[i]) > 1 and splitrow[i][-2] + splitrow[i][-1] == \"..\":\n","            realtext.append(splitrow[i] + \" \" + splitrow[i+1].strip())\n","            i += 1\n","                    \n","        # 2. 小數或超大數\n","        elif i+1 < len(splitrow) and splitrow[i][-1] in [\".\", \",\"] and splitrow[i+1][0].isdigit():\n","            realtext.append(splitrow[i] + splitrow[i+1].strip())\n","            i += 1\n","\n","        # 3. 重複的標點符號但是有空格隔開\n","        elif i+1 < len(splitrow) and splitrow[i+1].strip() in [\"?\", \"!\", \".\"]:\n","            addSTR = splitrow[i]\n","            while i+1 < len(splitrow) and splitrow[i+1].strip() in [\"?\", \"!\", \".\"]:\n","                addSTR += splitrow[i+1]\n","                i += 1\n","            realtext.append(addSTR)\n","\n","        else:\n","            realtext.append(splitrow[i])\n","        i += 1\n","\n","\n","    # 只有一句話\n","    # 整句當作答案輸出\n","    if len(realtext) == 1:\n","        ans = \"\".join(realtext)\n","        writerow = \"\".join(realtext)\n","    # 兩句話，但整段文本很短\n","    # 整段當作答案輸出\n","    elif len(realtext) == 2 and len(re.split(' ', realtext[0] + realtext[1])) < 15:\n","        ans = ''.join(realtext)\n","        writerow = \"\".join(realtext)\n","\n","    # 太長的文本\n","    # elif len(realtext) > 10:\n","    #     # 先把長度縮減，避免塞不進 BERT\n","    #     while len(realtext) > 10:\n","    #         deleteID = -1\n","    #         maxLEN = 0\n","    #         for i in range(len(realtext)):\n","    #             tempSTR = re.split(' ', realtext[i])\n","    #             if len(tempSTR) > maxLEN:\n","    #                 deleteID = i\n","    #         realtext.remove(realtext[deleteID])\n","    #     writerow = \"\".join(realtext)\n","    else:    \n","        i = 0\n","        for i in range(len(realtext)):\n","            # 判斷片語或疑問詞\n","            # 句子太短\n","            if len(re.split(' ', realtext[i])) <= Sentence_Min_length:\n","                # 結尾是結束符號\n","                if realtext[i][-1] in [\"?\", \"!\", \".\"]:\n","                    ans += realtext[i].strip()\n","                # 結尾是停頓符號\n","                # 忽略\n","                elif realtext[i][-1] in [\",\", \":\", \";\"]:\n","                    pass\n","                # 其他\n","                else:\n","                    ans += realtext[i].strip()\n","\n","            # 句子夠長<=10，但結尾是'?',':'\n","            # 把句子連貫\n","            elif len(re.split(' ', realtext[i])) <= 7 and realtext[i][-1] == \"!\":\n","                if ans != \"\":\n","                    ans += \" \"\n","                ans += realtext[i].strip()\n","\n","            elif len(re.split(' ', realtext[i])) <= 10 and realtext[i][-1] == \"?\":\n","                if ans != \"\":\n","                    ans += \" \"\n","                ans += realtext[i].strip()\n","\n","            elif len(re.split(' ', realtext[i])) <= 10 and realtext[i][-1] == \":\":\n","                if ans != \"\":\n","                    ans += \" \"\n","                ans += realtext[i].strip()\n","                \n","            # 句子夠長，但結尾是','\n","            # 把句子連貫\n","            elif realtext[i][-1] == \",\" and len(re.split(' ', realtext[i])) <= 17:\n","                if ans != \"\":\n","                    ans += \" \"\n","                ans += realtext[i].strip()\n","            \n","            # 把這句納入訓練資料，結束\n","            else:\n","                # if ans != \"\":\n","                #     ans += \" \"\n","                # ans += realtext[i].strip()\n","                if ans != \"\":\n","                    ans += \" \"\n","                ans += realtext[i].strip()\n","                # else:\n","                    # temp = \"\".join(realtext)\n","                    # writerow += \"\".join(temp)\n","                if len(realtext) > 10 and len(realtext) < 20:\n","                    # 先把長度縮減，避免塞不進 BERT\n","                    while len(realtext) > 10:\n","                        deleteID = -1\n","                        maxLEN = 0\n","                        for i in range(len(realtext)):\n","                            tempSTR = re.split(' ', realtext[i])\n","                            if len(tempSTR) > maxLEN:\n","                                deleteID = i\n","                        realtext.remove(realtext[deleteID])\n","                writerow = \"\".join(realtext)\n","                break\n","\n","    # 再去除開頭沒必要的符號和標題\n","    while ans != \"\" and ans[0] in [\".\", \"Â\", \"`\", \"-\", \"(\", \")\", \"#\", \"‘\", \"’\", \"“\", \"”\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"]:\n","        ans = ans[1:].strip()\n","    # 再去除結尾沒必要的符號和標題\n","    # 注意不能把句號給去掉了\n","    while ans != \"\" and ans[-1] in [\"Â\", \"`\", \"-\", \"(\", \")\", \"#\", \"‘\", \"’\", \"“\", \"”\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"]:\n","        ans = ans[:-1].strip()\n","\n","    return [ans, writerow]\n","\n","\n","\n","# 區分資料\n","def generatePreProcessDF(fileDatafram):\n","  test_data = fileDatafram\n","  row_length = test_data.shape[0]\n","  with open('ans_output.csv', 'w', encoding='utf-8', newline='') as outfile:\n","      writer = csv.writer(outfile)\n","      with open('test_output.csv', 'w', encoding='utf-8', newline='') as outfile2:\n","          writer2 = csv.writer(outfile2)\n","\n","          writer.writerow([\"id\", 'q', 'r', 's'])\n","          writer2.writerow([\"id\", 'q', 'r', 's'])\n","          oldID = 0\n","          for row in range(row_length):\n","              rowID = test_data.iloc[row][\"id\"]\n","              rowQ = test_data.iloc[row][\"q\"]\n","              rowR = test_data.iloc[row][\"r\"]\n","              rowS = test_data.iloc[row][\"s\"]\n","              \n","              # 避免處理重複ID\n","              if oldID == rowID:\n","                  continue\n","              else:\n","                  oldID = rowID\n","\n","                  # 把雙引號處理掉\n","                  rowQ = rowQ[1:-1]\n","                  rowR = rowR[1:-1]         \n","                              \n","                  # 先把所有網址全部刪除\n","                  httpQ = deleteHTTP(rowQ)       \n","                  httpR = deleteHTTP(rowR)\n","\n","                                  \n","                  # 輸出給模型的答案\n","                  ansQ, modelQ = generateAns(httpQ)\n","                  ansR, modelR = generateAns(httpR)\n","                  # isTest = False\n","                  # # 寫入資料\n","                  # if modelQ != \"\":\n","                  #     ansQ = modelQ\n","                  #     isTest = True\n","                  # if modelR != \"\":\n","                  #     ansR = modelR\n","                  #     isTest = True\n","                  \n","                  # 檢查空答案\n","                  if ansQ == \"\":\n","                      ansQ = test_data.iloc[row][\"q\"][1:-1]\n","                      isTest = True\n","                  if ansR == \"\":\n","                      ansR = test_data.iloc[row][\"r\"][1:-1]\n","                      isTest = True\n","\n","                  writer.writerow([rowID, ansQ, ansR, rowS])\n","\n","                  if len(rowQ.split(\" \")) > 100:\n","                    rowQ = rowQ[:50] + rowQ[-50:]\n","                  if len(rowR.split(\" \")) > 100:\n","                    rowR = rowR[:50] + rowR[-50:]\n","                  writer2.writerow([rowID, rowQ, rowR, rowS])\n","                  # if isTest:\n","                  #     writer2.writerow([rowID, ansQ, ansR, rowS])\n","                  # else:\n","                  #     writer.writerow([rowID, ansQ, ansR, rowS])\n","                                \n","          outfile2.close()\n","      outfile.close()"]},{"cell_type":"markdown","metadata":{"id":"RNtLPyIfsUUW"},"source":["# Predicting"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"6GZc8U7rsfWc","executionInfo":{"status":"error","timestamp":1670485421878,"user_tz":-480,"elapsed":278,"user":{"displayName":"朱自宇","userId":"15701013196506880556"}},"colab":{"base_uri":"https://localhost:8080/","height":572},"outputId":"98b9b529-63d1-448f-8fad-d0facc20ced8"},"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'id'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-e679756377a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mmaxScore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmaxScore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mans_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAnwser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-19-e679756377a2>\u001b[0m in \u001b[0;36mgetAnwser\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \"\"\"\n\u001b[1;32m     17\u001b[0m   \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./Batch_answers - train_data (no-blank).csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m   empty_title = ((df['id'].isnull()) \\\n\u001b[0m\u001b[1;32m     19\u001b[0m                 \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'id'"]}],"source":["def getAnwser() -> dict:\n","  \"\"\"\n","  dict:{\n","    rowID:[\n","      {\n","        q': sent,\n","        r': sent,\n","      },\n","      {\n","        q': sent,\n","        r': sent,\n","      },\n","      ...\n","    ]\n","  }\n","  \"\"\"\n","  df = pd.read_csv(\"./Batch_answers - train_data (no-blank).csv\")\n","  empty_title = ((df['id'].isnull()) \\\n","                | (df['q'].isnull()) \\\n","                | (df['q'] == '') \\\n","                | (df['q'] == '0'))\n","  df = df[~empty_title]\n","  AnwserMap = dict()\n","  for i in range(len(df.index)):\n","    rowID = df.iloc[i].id\n","    if not rowID in AnwserMap.keys():\n","      AnwserMap[rowID] = list()\n","    testcase = dict()      \n","    testcase[\"q'\"] = df.iloc[i][\"q'\"][1:-1]\n","    testcase[\"r'\"] = df.iloc[i][\"r'\"][1:-1]\n","    AnwserMap[rowID].append(testcase)\n","\n","  return AnwserMap\n","\n","\n","def lcs(X, Y):\n","  m = len(X)\n","  n = len(Y)\n","  L = [[None]*(n + 1) for i in range(m + 1)]\n","  for i in range(m + 1):\n","    for j in range(n + 1):\n","      if i == 0 or j == 0 :\n","        L[i][j] = 0\n","      elif X[i-1] == Y[j-1]:\n","        L[i][j] = L[i-1][j-1]+1\n","      else:\n","        L[i][j] = max(L[i-1][j], L[i][j-1])\n","  return L[m][n]\n","\n","\n","def Scoring(ans, id, q, r) -> float:\n","  if not id in ans.keys():\n","    return 0\n","  cases = ans[id]\n","  maxScore = 0\n","  for case in cases:\n","    LCS1 = lcs(case[\"q'\"], q)\n","    LCS2 = lcs(case[\"r'\"], r)\n","    score = 0.5 *((LCS1 / (len(case[\"q'\"]) + len(q) - LCS1)) +  (LCS2 / (len(case[\"r'\"]) + len(r) - LCS2)))\n","    if score > maxScore:\n","      maxScore = score\n","  return maxScore\n","ans_dict = getAnwser()\n"]},{"cell_type":"code","execution_count":31,"metadata":{"id":"NaBatGaz4GGJ","executionInfo":{"status":"ok","timestamp":1670485923907,"user_tz":-480,"elapsed":446,"user":{"displayName":"朱自宇","userId":"15701013196506880556"}}},"outputs":[],"source":["def testing():  \n","  df = pd.read_csv(\"test_output.csv\")\n","  #print(\"input cases:\", df.index)\n","  df = df.reset_index()\n","  df = df.loc[:, [\"id\", \"q\", \"r\", 's']]\n","  df.columns = [\"id\", \"q\", 'r', 's']\n","\n","  ## predict testcases q'\n","  list_testidq = list()\n","  list_testq = list()\n","  list_testsubq = list()\n","  for i in range(len(df.index)):\n","    for subq in getSubsentences(df.iloc[i].q):\n","      list_testidq.append(df.iloc[i].id)\n","      list_testq.append(df.iloc[i].q)\n","      list_testsubq.append(subq)\n","  df_testq = pd.DataFrame(dict({\"q\": list_testq, \"q'\":list_testsubq}))\n","  df_testq.to_csv(\"test_q.tsv\", sep=\"\\t\", index=False)\n","  model = torch.load('/content/drive/MyDrive/T-Brain-NLP/model_q.dat', map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","  testset = SentenceSimilarityDataset(\"test\", \"test_q.tsv\")\n","  testloader = DataLoader(testset, batch_size=10, collate_fn=create_mini_batch)\n","  predictions_q = get_predictions(model, testloader).tolist()\n","  torch.cuda.empty_cache()\n","  df_predq = pd.DataFrame(dict({\"id\":list_testidq, \"q\":list_testq, \"q'\":list_testsubq, \"f\": predictions_q}))\n","\n","\n","  ## predict testcases r'\n","  list_testidr = list()\n","  list_testr = list()\n","  list_testsubr = list()\n","  for i in range(len(df.index)):\n","    df.iloc[i].r = str(df.iloc[i].r)\n","    for subr in getSubsentences(df.iloc[i].r):\n","      list_testidr.append(df.iloc[i].id)\n","      list_testr.append(df.iloc[i].r)\n","      list_testsubr.append(subr)\n","  df_testr = pd.DataFrame(dict({\"r\": list_testr, \"r'\":list_testsubr}))\n","  df_testr.to_csv(\"test_r.tsv\", sep=\"\\t\", index=False)\n","\n","  model = torch.load('/content/drive/MyDrive/T-Brain-NLP/model_r.dat', map_location=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))\n","  testset = SentenceSimilarityDataset(\"test\", \"test_r.tsv\")\n","  testloader = DataLoader(testset, batch_size=10, collate_fn=create_mini_batch)\n","  predictions_r = get_predictions(model, testloader).tolist()\n","  torch.cuda.empty_cache()\n","  df_predr = pd.DataFrame(dict({\"id\":list_testidr, \"r\":list_testr, \"r'\":list_testsubr, \"f\": predictions_r}))\n","  ## calculate q' r' s\n","  ## pass\n","  ## predict_ans\n","  pre_ans = pd.read_csv(\"ans_output.csv\")\n","  pre_ans_dict = dict()\n","  for i in range(len(pre_ans.index)):\n","    pre_ans_dict[pre_ans.iloc[i].id] = dict()\n","    pre_ans_dict[pre_ans.iloc[i].id][\"q\"] = pre_ans.iloc[i].q\n","    pre_ans_dict[pre_ans.iloc[i].id][\"r\"] = pre_ans.iloc[i].r\n","\n","\n","\n","  ## merge id q r\n","  ans_id = list()\n","  ans_q  = list()\n","  ans_r  = list()\n","  for i in range(len(df.index)):\n","    row = df.iloc[i]\n","    ans_id.append(row[\"id\"])\n","    # find q'\n","    tempq = \"\"\n","    tempf = 4\n","    if row[\"id\"] in pre_ans_dict.keys():\n","      tempq = pre_ans_dict[row[\"id\"]]['q']\n","    if row[\"id\"] in list_testidq:\n","      count = 0\n","      for j in range(len(list_testidq)):\n","        if list_testidq[j] == row[\"id\"]:\n","          if predictions_q[j] > tempf:\n","            tempq += list_testsubq[j] + \" \"\n","            count += 1\n","            if count > 3:\n","              break\n","            #tempf = predictions_q[j] \n","    else:\n","      if tempq == \"\":\n","        for tempSub in getSubsentences(row[\"q\"]):\n","          if len(tempq) < 50:\n","            tempq += tempSub.strip() + \" \"\n","          else:\n","            break\n","    tempq.strip()\n","    ans_q.append('\"' + tempq +'\"')\n","    # find r'\n","    tempr = \"\"\n","    tempf = 4\n","    if row[\"id\"] in pre_ans_dict.keys():\n","      tempr = pre_ans_dict[row[\"id\"]]['r']\n","    if row[\"id\"] in list_testidr:\n","      count = 0\n","      for j in range(len(list_testidr)):\n","        if list_testidr[j] == row[\"id\"]:\n","          if predictions_r[j] > tempf:\n","            tempr += list_testsubr[j]+ \" \"\n","            count += 1\n","            if count > 3:\n","              break\n","            #tempf = predictions_r[j]\n","    else:\n","      if tempr == \"\":\n","        for tempSub in getSubsentences(row[\"r\"]):\n","          if len(tempr) < 50:\n","            tempr += tempSub.strip() + \" \"\n","          else:\n","            break\n","    tempr.strip()\n","    ans_r.append('\"' + tempr +'\"')\n","\n","\n","  dfans = pd.DataFrame(dict({\"id\":ans_id, \"q\":ans_q, \"r\":ans_r}))\n","  #print(\"ans cases:\", dfans.index)\n","  dfans.to_csv(\"ans.csv\", sep=\",\", index=False)\n"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"WHxZjICEhWIl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670486114665,"user_tz":-480,"elapsed":187117,"user":{"displayName":"朱自宇","userId":"15701013196506880556"}},"outputId":"7fb63ad3-9f46-48c2-cf14-02508c43812e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/pandas/core/series.py:1056: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  cacher_needs_updating = self._check_is_chained_assignment_possible()\n"]}],"source":["import random\n","def testandscore(mode):\n","  for i in range(1, 2):\n","    filename = \"/content/drive/MyDrive/T-Brain-NLP/Batch_answers - test_data(no_label).csv\"\n","    dataframe = pd.read_csv(filename)\n","    # dataframe = dataframe.sample(n = 100, random_state=i*1421)\n","    generatePreProcessDF(dataframe)\n","    testing()\n","    \n","    if mode == \"test\":\n","      return\n","    print(\"Test Cases\", i, \":\", end=\"  \\n\")\n","    output = pd.read_csv(\"ans.csv\")\n","    total = 0.0\n","    for i in range(output.shape[0]):\n","      total += Scoring(ans_dict, int(output.iloc[i][\"id\"]), str(output.iloc[i][\"q\"][1:-1]), str(output.iloc[i][\"r\"][1:-1]))\n","    print(\"\\tans:\", total/output.shape[0], end=\"  \\n\")\n","\n","    outfile_id = list()\n","    outfile_q = list()\n","    outfile_r = list()\n","    outfile_score = list()\n","\n","    output = pd.read_csv(\"ans_output.csv\")\n","    total = 0.0\n","    for i in range(output.shape[0]):\n","      scr = Scoring(ans_dict, int(output.iloc[i][\"id\"]), str(output.iloc[i][\"q\"]), str(output.iloc[i][\"r\"]))\n","      total += scr\n","      outfile_id.append(output.iloc[i][\"id\"])\n","      outfile_q.append(output.iloc[i][\"q\"])\n","      outfile_r.append(output.iloc[i][\"r\"])\n","      outfile_score.append(scr)\n","    print(\"\\tans_output:\", total/output.shape[0], end=\"  \\n\")\n","    df_out = pd.DataFrame(dict({\n","        \"id\":outfile_id,\n","        \"q\":outfile_q,\n","        \"r\":outfile_r,\n","        \"score\":outfile_score\n","    }))\n","    df_out.to_csv(\"ansout_with_score_\"+ str(i+int('0')) + \".csv\", sep=\",\", index=False)\n","\n","testandscore(\"test\")"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d380c40fcc684c2c992c55daa1fee568":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_71f9b917b402439191d97dc1c6dbf9d4","IPY_MODEL_1c5eb6beea874ce888617b1d61040e87","IPY_MODEL_bd94ade2425b422995069d9b258cd6f3"],"layout":"IPY_MODEL_1979d4beacc244179d42202c43910762"}},"71f9b917b402439191d97dc1c6dbf9d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7a28622dc554b1a804af4552adc8ffd","placeholder":"​","style":"IPY_MODEL_6691ec28cd384d20a29c1a3c0130fa6c","value":"Downloading: 100%"}},"1c5eb6beea874ce888617b1d61040e87":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3a7723f2371d46cea350006322e8ba5f","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d4fb458b31d146c7881702f4b60d1796","value":440473133}},"bd94ade2425b422995069d9b258cd6f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79324c6387d149f0b212cb2b0abaff14","placeholder":"​","style":"IPY_MODEL_acabe54c777940c6bf28fa6bc323c61b","value":" 440M/440M [00:22&lt;00:00, 17.9MB/s]"}},"1979d4beacc244179d42202c43910762":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7a28622dc554b1a804af4552adc8ffd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6691ec28cd384d20a29c1a3c0130fa6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3a7723f2371d46cea350006322e8ba5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4fb458b31d146c7881702f4b60d1796":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"79324c6387d149f0b212cb2b0abaff14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"acabe54c777940c6bf28fa6bc323c61b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9544d0f715e7407c8bdf10d3312a12a1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b5b48497c18947b587173500d37b5f0d","IPY_MODEL_b45a0ed4e2324897a05ecd5cb2877c8f","IPY_MODEL_f7075a22ee3048d0b297ed19bbaa1b82"],"layout":"IPY_MODEL_ad38d59a91f740628869925c8373d149"}},"b5b48497c18947b587173500d37b5f0d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_32af8c4e426c47ae8665590dc36814cb","placeholder":"​","style":"IPY_MODEL_609bb8e120fe484ea72fb4212da7f48c","value":"Downloading: 100%"}},"b45a0ed4e2324897a05ecd5cb2877c8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5906c5ff8e3d47039127db76d6bfec16","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9b9664e5d5d044d2b051b5eb3bd0ef42","value":231508}},"f7075a22ee3048d0b297ed19bbaa1b82":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37de6056527b44a2a4548b4d6aaf06d1","placeholder":"​","style":"IPY_MODEL_041fcf91d4c5426ca705365c76a1a5d8","value":" 232k/232k [00:00&lt;00:00, 1.67MB/s]"}},"ad38d59a91f740628869925c8373d149":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32af8c4e426c47ae8665590dc36814cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"609bb8e120fe484ea72fb4212da7f48c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5906c5ff8e3d47039127db76d6bfec16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b9664e5d5d044d2b051b5eb3bd0ef42":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37de6056527b44a2a4548b4d6aaf06d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"041fcf91d4c5426ca705365c76a1a5d8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"21dab3de7917438fa813e13d112023bc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f8efb18533c44468bbbb3c65fbd7ce1e","IPY_MODEL_8293949f27d840faba28c67b1bc7e349","IPY_MODEL_89eb4ea7348a408491cf79a023a26764"],"layout":"IPY_MODEL_a31a2dc521dc4d36b805425a767da4a7"}},"f8efb18533c44468bbbb3c65fbd7ce1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aaaae1666914459d8e96b9d89ceff593","placeholder":"​","style":"IPY_MODEL_997a146478d34a70bcb8c34c1c72c917","value":"Downloading: 100%"}},"8293949f27d840faba28c67b1bc7e349":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_09fe99c50a594758b31060fb336b0e6a","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_793d5a9909174d6c9e81c65e750e50f6","value":28}},"89eb4ea7348a408491cf79a023a26764":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_696780ae21a44599b074e011521b11aa","placeholder":"​","style":"IPY_MODEL_d84d564867d64f97b0b3925806c78aa7","value":" 28.0/28.0 [00:00&lt;00:00, 1.02kB/s]"}},"a31a2dc521dc4d36b805425a767da4a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aaaae1666914459d8e96b9d89ceff593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"997a146478d34a70bcb8c34c1c72c917":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"09fe99c50a594758b31060fb336b0e6a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"793d5a9909174d6c9e81c65e750e50f6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"696780ae21a44599b074e011521b11aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d84d564867d64f97b0b3925806c78aa7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"90446af5e6934690a721295b1f2ff5f0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9fd2859a34304d0aace16e0c2eed707c","IPY_MODEL_f07c1df2094b4afdb9121a4605619473","IPY_MODEL_af12231d2cdc498882c4464308c24643"],"layout":"IPY_MODEL_96a478bdaccf4d5484a8b1716ea1618d"}},"9fd2859a34304d0aace16e0c2eed707c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a479082a2d224991bd4a71c9a3a803b8","placeholder":"​","style":"IPY_MODEL_ba213c6c2f6941f8a2b2fba8e39c56bd","value":"Downloading: 100%"}},"f07c1df2094b4afdb9121a4605619473":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_de2e60d8c4134e3088a54db8ad65d6ee","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a72ecf9c88e042bfbdc1de844a71f011","value":570}},"af12231d2cdc498882c4464308c24643":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa83d81a2f3d4d849b3f0b6ca53cfc17","placeholder":"​","style":"IPY_MODEL_d04a84b0d1f54f04a1dd73949bd29361","value":" 570/570 [00:00&lt;00:00, 9.21kB/s]"}},"96a478bdaccf4d5484a8b1716ea1618d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a479082a2d224991bd4a71c9a3a803b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba213c6c2f6941f8a2b2fba8e39c56bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de2e60d8c4134e3088a54db8ad65d6ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a72ecf9c88e042bfbdc1de844a71f011":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fa83d81a2f3d4d849b3f0b6ca53cfc17":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d04a84b0d1f54f04a1dd73949bd29361":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}